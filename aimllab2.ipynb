{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2418210c-81c3-42a3-a98e-b7f0a0e33806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic baseline test accuracy: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\diyyy\\programs\\python progs\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras MLP test accuracy: 0.9830\n",
      "Saved: outputs/mnist/cm_mlp.png\n"
     ]
    }
   ],
   "source": [
    "# mnist_mlp_vs_logistic.py\n",
    "# Keras MLP (dropout + early stopping) on MNIST, compared to a Logistic baseline.\n",
    "# Saves confusion matrix for the MLP.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def ensure_out():\n",
    "    os.makedirs(\"outputs/mnist\", exist_ok=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    ensure_out()\n",
    "\n",
    "    # Load MNIST (uses ~/.keras/datasets/mnist.npz if offline)\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # ----- Logistic baseline -----\n",
    "    X_train_flat = X_train.reshape((len(X_train), -1)).astype(\"float32\") / 255.0\n",
    "    X_test_flat = X_test.reshape((len(X_test), -1)).astype(\"float32\") / 255.0\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "    X_test_scaled = scaler.transform(X_test_flat)\n",
    "\n",
    "    logreg = LogisticRegression(\n",
    "    solver=\"lbfgs\", max_iter=100, n_jobs=-1\n",
    ")\n",
    "\n",
    "    logreg.fit(X_train_scaled, y_train)\n",
    "    acc_lr = accuracy_score(y_test, logreg.predict(X_test_scaled))\n",
    "    print(f\"Logistic baseline test accuracy: {acc_lr:.4f}\")\n",
    "\n",
    "    # ----- MLP with dropout + early stopping -----\n",
    "    X_train_n = X_train.astype(\"float32\") / 255.0\n",
    "    X_test_n = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(28, 28)),\n",
    "        Dense(512, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(10, activation=\"softmax\"),\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    es = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
    "    model.fit(X_train_n, y_train, validation_split=0.1,\n",
    "              epochs=30, batch_size=128, callbacks=[es], verbose=0)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test_n, y_test, verbose=0)\n",
    "    print(f\"Keras MLP test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # Confusion matrix for MLP\n",
    "    y_pred_mlp = np.argmax(model.predict(X_test_n, verbose=0), axis=1)\n",
    "    cm = confusion_matrix(y_test, y_pred_mlp)\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=np.arange(10))\n",
    "    disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
    "    plt.title(\"MNIST Confusion Matrix - Keras MLP\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"outputs/mnist/cm_mlp.png\", dpi=200)\n",
    "    plt.close()\n",
    "    print(\"Saved: outputs/mnist/cm_mlp.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59912119-2c92-4c9f-a805-0c34756bb907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM CV accuracy: 0.9794 ± 0.0033\n",
      "RBF SVM CV accuracy:    0.9839 ± 0.0060\n",
      "Best RBF params: {'C': 10, 'gamma': 0.01}, best CV accuracy: 0.9827\n",
      "Saved: outputs/svm/heatmap_rbf.png\n",
      "Saved: outputs/svm/sv_linear.png, outputs/svm/sv_rbf.png\n"
     ]
    }
   ],
   "source": [
    "# svm_kernels_margins_digits.py\n",
    "# Digits dataset: Linear vs RBF SVM, grid search, PCA support-vector plots, accuracy heatmap.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def ensure_out():\n",
    "    os.makedirs(\"outputs/svm\", exist_ok=True)\n",
    "\n",
    "\n",
    "def heatmap(Z, Cs, gammas, title, fname):\n",
    "    plt.figure()\n",
    "    im = plt.imshow(Z, origin=\"lower\", aspect=\"auto\")\n",
    "    plt.colorbar(im, label=\"CV Accuracy\")\n",
    "    plt.xticks(np.arange(len(gammas)), gammas)\n",
    "    plt.yticks(np.arange(len(Cs)), Cs)\n",
    "    plt.xlabel(\"gamma\")\n",
    "    plt.ylabel(\"C\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_sv_2d(clf, X2d, y, title, fname):\n",
    "    plt.figure()\n",
    "    for c in np.unique(y):\n",
    "        idx = y == c\n",
    "        plt.scatter(X2d[idx, 0], X2d[idx, 1], s=10, edgecolors=\"k\", alpha=0.6, label=str(c))\n",
    "    sv = clf.support_vectors_\n",
    "    plt.scatter(sv[:, 0], sv[:, 1], s=60, facecolors=\"none\", edgecolors=\"r\",\n",
    "                linewidths=1.5, label=\"Support Vectors\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.legend(loc=\"best\", fontsize=7, ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    ensure_out()\n",
    "\n",
    "    X, y = load_digits(return_X_y=True)\n",
    "    Xs = StandardScaler().fit_transform(X)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Baseline SVMs\n",
    "    lin = SVC(kernel=\"linear\", C=1.0)\n",
    "    rbf = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\")\n",
    "\n",
    "    lin_scores = cross_val_score(lin, Xs, y, cv=cv, scoring=\"accuracy\")\n",
    "    rbf_scores = cross_val_score(rbf, Xs, y, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "    print(f\"Linear SVM CV accuracy: {lin_scores.mean():.4f} ± {lin_scores.std():.4f}\")\n",
    "    print(f\"RBF SVM CV accuracy:    {rbf_scores.mean():.4f} ± {rbf_scores.std():.4f}\")\n",
    "\n",
    "    # Grid search (RBF)\n",
    "    param_grid = {\"C\": [0.1, 1, 10, 100],\n",
    "                  \"gamma\": [1e-3, 1e-2, 1e-1, 1.0]}\n",
    "\n",
    "    grid = GridSearchCV(SVC(kernel=\"rbf\"), param_grid=param_grid,\n",
    "                        cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid.fit(Xs, y)\n",
    "\n",
    "    print(f\"Best RBF params: {grid.best_params_}, best CV accuracy: {grid.best_score_:.4f}\")\n",
    "\n",
    "    Z = grid.cv_results_[\"mean_test_score\"].reshape(len(param_grid[\"C\"]),\n",
    "                                                    len(param_grid[\"gamma\"]))\n",
    "    heatmap(Z, param_grid[\"C\"], param_grid[\"gamma\"],\n",
    "            \"RBF SVM Grid Search Accuracy\",\n",
    "            \"outputs/svm/heatmap_rbf.png\")\n",
    "    print(\"Saved: outputs/svm/heatmap_rbf.png\")\n",
    "\n",
    "    # PCA + Support vector visualization\n",
    "    Xtr, Xte, ytr, yte = train_test_split(Xs, y, test_size=0.25,\n",
    "                                          stratify=y, random_state=42)\n",
    "    Xtr2 = PCA(n_components=2, random_state=42).fit_transform(Xtr)\n",
    "\n",
    "    lin2 = SVC(kernel=\"linear\", C=1.0).fit(Xtr2, ytr)\n",
    "    rbf2 = SVC(kernel=\"rbf\",\n",
    "               C=grid.best_params_[\"C\"],\n",
    "               gamma=grid.best_params_[\"gamma\"]).fit(Xtr2, ytr)\n",
    "\n",
    "    plot_sv_2d(lin2, Xtr2, ytr, \"Digits: Linear SVM Support Vectors (PCA-2D)\", \"outputs/svm/sv_linear.png\")\n",
    "    plot_sv_2d(rbf2, Xtr2, ytr, \"Digits: RBF SVM Support Vectors (PCA-2D)\", \"outputs/svm/sv_rbf.png\")\n",
    "\n",
    "    print(\"Saved: outputs/svm/sv_linear.png, outputs/svm/sv_rbf.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c6c19ff-c32a-44ee-9ef6-82de50acf14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\diyyy\\programs\\python progs\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\diyyy\\programs\\python progs\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\diyyy\\programs\\python progs\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\diyyy\\programs\\python progs\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\diyyy\\programs\\python progs\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\diyyy\\programs\\python progs\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\diyyy\\programs\\python progs\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\diyyy\\programs\\python progs\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\diyyy\\programs\\python progs\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\diyyy\\programs\\python progs\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 5-fold CV accuracy: 0.9533 ± 0.0452\n",
      "\n",
      "Logistic Regression per-class metrics:\n",
      "  class    prec     rec      f1  support\n",
      "      0   1.000   1.000   1.000       50\n",
      "      1   0.922   0.940   0.931       50\n",
      "      2   0.939   0.920   0.929       50\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        50\n",
      "  versicolor       0.92      0.94      0.93        50\n",
      "   virginica       0.94      0.92      0.93        50\n",
      "\n",
      "    accuracy                           0.95       150\n",
      "   macro avg       0.95      0.95      0.95       150\n",
      "weighted avg       0.95      0.95      0.95       150\n",
      "\n",
      "Saved: outputs/iris/cm_logistic_regression.png\n",
      "Linear SVM 5-fold CV accuracy: 0.9267 ± 0.0533\n",
      "\n",
      "Linear SVM per-class metrics:\n",
      "  class    prec     rec      f1  support\n",
      "      0   1.000   0.980   0.990       50\n",
      "      1   0.898   0.880   0.889       50\n",
      "      2   0.885   0.920   0.902       50\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      0.98      0.99        50\n",
      "  versicolor       0.90      0.88      0.89        50\n",
      "   virginica       0.88      0.92      0.90        50\n",
      "\n",
      "    accuracy                           0.93       150\n",
      "   macro avg       0.93      0.93      0.93       150\n",
      "weighted avg       0.93      0.93      0.93       150\n",
      "\n",
      "Saved: outputs/iris/cm_linear_svm.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\diyyy\\programs\\python progs\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# iris_logreg_svm.py\n",
    "# Logistic Regression & Linear SVM on Iris with standardization,\n",
    "# 5-fold CV, confusion matrices, per-class metrics, and PCA(2D) plots.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def ensure_out():\n",
    "    os.makedirs(\"outputs/iris\", exist_ok=True)\n",
    "\n",
    "\n",
    "def pr_table(y_true, y_pred, labels):\n",
    "    p, r, f1, sup = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=labels, zero_division=0\n",
    "    )\n",
    "    print(f\"{'class':>7} {'prec':>7} {'rec':>7} {'f1':>7} {'support':>8}\")\n",
    "    for c, pp, rr, ff, ss in zip(labels, p, r, f1, sup):\n",
    "        print(f\"{c:>7} {pp:7.3f} {rr:7.3f} {ff:7.3f} {ss:8d}\")\n",
    "\n",
    "\n",
    "def decision_plot_2d(model, X2d, y, title, fname, h=0.03):\n",
    "    x_min, x_max = X2d[:, 0].min() - 1, X2d[:, 0].max() + 1\n",
    "    y_min, y_max = X2d[:, 1].min() - 1, X2d[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.contourf(xx, yy, Z, alpha=0.25)\n",
    "\n",
    "    for c in np.unique(y):\n",
    "        idx = (y == c)\n",
    "        plt.scatter(X2d[idx, 0], X2d[idx, 1], s=20, edgecolors='k', label=str(c))\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.legend(fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    ensure_out()\n",
    "    data = load_iris()\n",
    "    X, y, names = data.data, data.target, data.target_names\n",
    "\n",
    "    pipe_lr = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(multi_class=\"multinomial\",\n",
    "                                  solver=\"lbfgs\", max_iter=1000))\n",
    "    ])\n",
    "\n",
    "    pipe_lsvm = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LinearSVC(C=1.0))\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for label, model in [\n",
    "        (\"Logistic Regression\", pipe_lr),\n",
    "        (\"Linear SVM\", pipe_lsvm)\n",
    "    ]:\n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring=\"accuracy\")\n",
    "        print(f\"{label} 5-fold CV accuracy: {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "\n",
    "        y_pred = cross_val_predict(model, X, y, cv=cv)\n",
    "        cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "        print(f\"\\n{label} per-class metrics:\")\n",
    "        pr_table(y, y_pred, labels=[0, 1, 2])\n",
    "\n",
    "        print(\"\\nClassification report:\")\n",
    "        print(classification_report(y, y_pred, target_names=names, zero_division=0))\n",
    "\n",
    "        disp = ConfusionMatrixDisplay(cm, display_labels=names)\n",
    "        disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
    "        out = f\"outputs/iris/cm_{label.replace(' ', '_').lower()}.png\"\n",
    "        plt.title(f\"Iris Confusion Matrix - {label}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out, dpi=200)\n",
    "        plt.close()\n",
    "        print(f\"Saved: {out}\")\n",
    "\n",
    "    # 2D PCA for visualization only\n",
    "    X2d = PCA(n_components=2, random_state=42).fit_transform(X)\n",
    "\n",
    "    lr2d = LogisticRegression(multi_class=\"multinomial\",\n",
    "                              solver=\"lbfgs\", max_iter=1000).fit(X2d, y)\n",
    "    decision_plot_2d(lr2d, X2d, y,\n",
    "                     \"Iris Decision Regions (PCA) - LogReg\",\n",
    "                     \"outputs/iris/decision_lr.png\")\n",
    "\n",
    "    lsvm2d = LinearSVC(C=1.0).fit(X2d, y)\n",
    "    decision_plot_2d(lsvm2d, X2d, y,\n",
    "                     \"Iris Decision Regions (PCA) - LinearSVM\",\n",
    "                     \"outputs/iris/decision_lsvm.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5636652d-62ce-4f5c-a57b-b48d8e00b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms_spam_tfidf_logreg.py\n",
    "# TF-IDF + Logistic Regression spam detector. Prints precision/recall/F1 and\n",
    "# top positive/negative features. Saves confusion matrix figure.\n",
    "#\n",
    "# If offline: put the UCI \"SMSSpamCollection\" file (tab-separated \"label<TAB>message\")\n",
    "# next to this script and set LOCAL_PATH below. Otherwise the script tries a known URL.\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix, ConfusionMatrixDisplay\n",
    "LOCAL_PATH = \"SMSSpamCollection\" # fallback local filename (optional)\n",
    "REMOTE_TSV = \"https://huggingface.co/datasets/DarkNeuron-AI/spam-sms-collection-01/resolve/main/spam.csv\"\n",
    "def load_data():\n",
    "    if os.path.exists(LOCAL_PATH):\n",
    "        return pd.read_csv(LOCAL_PATH, sep=\"\\t\", header=None, names=[\"label\", \"message\"])\n",
    "    try:\n",
    "        df = pd.read_csv(REMOTE_TSV, encoding=\"latin1\")  # default sep=','\n",
    "        df = df.iloc[:, :2]  # keep only first two columns expected: label, message\n",
    "        df.columns = [\"label\", \"message\"]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"Could not load SMS dataset. Place 'SMSSpamCollection' next to this script or ensure internet is available.\") from e\n",
    "\n",
    "def main():\n",
    "    os.makedirs(\"outputs/sms\", exist_ok=True)\n",
    "    df = load_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[\"message\"].values, df[\"label\"].values,test_size=0.2, random_state=42, stratify=df[\"label\"].values)\n",
    "    print(\"Training labels:\", np.unique(y_train))\n",
    "    vect = TfidfVectorizer(lowercase=True, stop_words=\"english\",ngram_range=(1,2),max_df=0.95, min_df=2)\n",
    "\n",
    "    Xtr = vect.fit_transform(X_train)\n",
    "    Xte = vect.transform(X_test)\n",
    "    clf = LogisticRegression(penalty=\"l2\", solver=\"liblinear\",max_iter=1000)\n",
    "    clf.fit(Xtr, y_train)\n",
    "    y_pred = clf.predict(Xte)\n",
    "    print(\"\\nClassification report (test):\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(f\"Test accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[\"ham\",\"spam\"])\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=[\"ham\",\"spam\"])\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(\"SMS Spam Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"outputs/sms/cm_sms.png\", dpi=200); plt.close()\n",
    "    print(\"Saved: outputs/sms/cm_sms.png\")\n",
    "    # Top positive/negative (toward \"spam\")\n",
    "    feature_names = np.array(vect.get_feature_names_out())\n",
    "    coefs = clf.coef_[0]\n",
    "    top_pos = np.argsort(coefs)[-20:][::-1]\n",
    "    top_neg = np.argsort(coefs)[:20]\n",
    "    print(\"\\nTop 20 SPAM-indicative features:\")\n",
    "    for f, w in zip(feature_names[top_pos], coefs[top_pos]):\n",
    "        print(f\"{f:30s} {w: .3f}\")\n",
    "    print(\"\\nTop 20 HAM-indicative features:\")\n",
    "    for f, w in zip(feature_names[top_neg], coefs[top_neg]):\n",
    "        print(f\"{f:30s} {w: .3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
